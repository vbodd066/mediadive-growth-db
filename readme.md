# MediaDive Growth DB

**ML pipeline for predicting and generating viable microbial growth media from metagenomics data.**

The goal is to build a foundational model that can propose culture media formulations for previously unculturable microbes â€” using metagenomic signals to determine what key factors (composition, pH, carbon/nitrogen sources, trace elements) are required for successful cultivation.

---

## ğŸš€ Quick Start (Pick Your Path)

### Path 1: Just Run It (5 min)
```bash
make integrate-mediadive-ncbi  # Link MediaDive to NCBI genomes
make integrate-stats           # View results
make train-cvae-all            # Train model
```

### Path 2: Understand First (30 min)
1. Read: [`docs/GETTING_STARTED.md`](docs/GETTING_STARTED.md) (Path 2)
2. Read: [`docs/guides/mediadive_ncbi_linking.md`](docs/guides/mediadive_ncbi_linking.md)
3. Run commands above

### Path 3: Customize & Deep Dive (1-2 hours)
1. Read: [`docs/GETTING_STARTED.md`](docs/GETTING_STARTED.md) (Path 3)
2. Read: [`docs/guides/`](docs/guides/) for specialized guides
3. Modify and run

---

## ğŸ“š Documentation

**All documentation is in [`docs/`](docs/) folder:**

| Document | Purpose | Time |
|----------|---------|------|
| **[docs/GETTING_STARTED.md](docs/GETTING_STARTED.md)** | Entry point with 3 paths | 5 min |
| **[docs/INDEX.md](docs/INDEX.md)** | Complete navigation hub | 2 min |
| **[docs/COMMAND_REFERENCE.md](docs/COMMAND_REFERENCE.md)** | All CLI commands & Python API | 10 min |
| **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** | Common issues & solutions | 5-10 min |
| **[docs/guides/mediadive_ncbi_linking.md](docs/guides/mediadive_ncbi_linking.md)** | Data integration guide | 20 min |
| **[docs/guides/CVAE_GUIDE.md](docs/guides/CVAE_GUIDE.md)** | Model architecture details | 20 min |
| **[docs/guides/api_reference.md](docs/guides/api_reference.md)** | Data source APIs | 20 min |

ğŸ‘‰ **New to the project?** Start with [`docs/GETTING_STARTED.md`](docs/GETTING_STARTED.md)

---

## Architecture

```
Data Layer          ML Layer              Research Layer
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MediaDive API  â†’  Feature Engineering  â†’  Notebooks / EDA
    â†“                   â†“
SQLite DB         Processed Datasets
                        â†“
                  Model Training
                  â”œâ”€â”€ Growth Predictor (sklearn / neural)
                  â””â”€â”€ Media Generator (VAE)
                        â†“
                  Evaluation & Analysis
```

## Setup

```bash
# 1. Clone and install
git clone <repo-url> && cd mediadive-growth-db
pip install -e ".[ml,viz,dev]"

# 2. Copy environment config
cp .env.example .env
# Edit .env to add NCBI_EMAIL (required), NCBI_API_KEY (optional)

# 3. Initialize database
make init-db
```

## Available Pipelines

### MediaDive-NCBI Integration (Latest - Recommended)
```bash
# Link MediaDive strains to NCBI genomes, propagate growth data, build dataset
make integrate-mediadive-ncbi

# Check results
make integrate-stats

# Build features and train
make features
make train-cvae-all
```
ğŸ“– **Full guide**: [`docs/guides/mediadive_ncbi_linking.md`](docs/guides/mediadive_ncbi_linking.md)

### Multi-organism Ingestion (BacDive, NCBI, PubMed)
```bash
# Ingest all organism types with growth conditions
make ingest-all-organisms

# Or selectively:
make ingest-bacteria-bacdive      # BacDive bacteria
make ingest-fungi-ncbi             # NCBI fungi
make ingest-protists-ncbi          # NCBI protists
```

### Traditional MediaDive Only
```bash
# Ingest media data
make ingest

# Build ML-ready features
make features

# Train models
make train                                          # sklearn baseline
```

## Project Structure

```
mediadive-growth-db/
â”œâ”€â”€ pyproject.toml          # Packaging, deps, tool config
â”œâ”€â”€ Makefile                # Common commands
â”œâ”€â”€ DATA_SOURCES.md         # Guide to BacDive, NCBI, PubMed integration
â”œâ”€â”€ .env.example            # Environment template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # Centralized configuration
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ client.py       # MediaDive REST client (retries, rate-limiting)
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ schema.sql      # SQLite schema (extended with genomes, embeddings)
â”‚   â”‚   â”œâ”€â”€ init_db.py      # DB initialization
â”‚   â”‚   â””â”€â”€ queries.py      # Reusable read queries
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ fetch_media.py
â”‚   â”‚   â”œâ”€â”€ fetch_ingredients.py
â”‚   â”‚   â”œâ”€â”€ fetch_media_ingredients.py
â”‚   â”‚   â”œâ”€â”€ fetch_strain_growth.py
â”‚   â”‚   â”œâ”€â”€ fetch_bacdive.py              # NEW: BacDive API integration
â”‚   â”‚   â”œâ”€â”€ fetch_ncbi_organisms.py       # NEW: NCBI E-utilities (fungi/protists)
â”‚   â”‚   â””â”€â”€ enrich_growth_conditions.py   # NEW: Literature mining + curation
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ media_vectors.py      # Media â†’ composition vectors
â”‚   â”‚   â”œâ”€â”€ strain_features.py    # Strain-level features
â”‚   â”‚   â”œâ”€â”€ genome_features.py    # NEW: K-mer embeddings for genomes
â”‚   â”‚   â””â”€â”€ build_dataset.py      # NEW: Genome-media dataset builder
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py               # Abstract model interface
â”‚   â”‚   â”œâ”€â”€ growth_predictor.py   # sklearn + neural classifiers
â”‚   â”‚   â”œâ”€â”€ media_generator.py    # VAE + NEW: ConditionalMediaVAE
â”‚   â”‚   â””â”€â”€ evaluate.py           # Metrics & reporting
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ trainer.py            # Unified training runner
â”‚       â””â”€â”€ cloud/
â”‚           â””â”€â”€ launch.py         # Modal GPU launcher
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_ingest.py              # Full ingestion pipeline
â”‚   â”œâ”€â”€ build_features.py          # Feature building CLI
â”‚   â”œâ”€â”€ train.py                   # Training entry point
â”‚   â””â”€â”€ ingest_all_organisms.py    # NEW: Multi-source ingest orchestrator
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py              # Shared fixtures (test DB)
â”‚   â”œâ”€â”€ test_api_client.py
â”‚   â”œâ”€â”€ test_db.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_data_integrity.py   # Post-ingest data validation
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ mediadive_deep_learning_models.ipynb     # NEW: CVAE training
â”‚   â””â”€â”€ top_media_analysis.ipynb                 # EDA & prototyping
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ raw/                # Raw API JSON + genome data
    â”‚   â”œâ”€â”€ media/
    â”‚   â”œâ”€â”€ ingredients/
    â”‚   â”œâ”€â”€ bacdive/        # NEW: BacDive cache
    â”‚   â””â”€â”€ strains/
    â”œâ”€â”€ interim/            # Intermediate processing
    â”œâ”€â”€ processed/          # ML-ready .npy / .parquet
    â”œâ”€â”€ models/             # Trained model artifacts
    â””â”€â”€ releases/           # Dataset releases
```

## Models

### Growth Predictor (Classification)
Given a media composition vector â†’ predict whether a strain will grow (binary).

- **Tier 1**: Gradient Boosted Trees via sklearn (fast iteration, strong baseline)
- **Tier 2**: Feed-forward neural network with BatchNorm + Dropout (extensible to multi-modal inputs)

### Media Generator (VAE)
Learn a smooth latent space over viable media compositions, then sample novel formulations.

- **Phase 1**: Unconditional VAE over composition vectors
- **Phase 2**: Conditional VAE â€” condition on strain taxonomy
- **Phase 3**: Condition on metagenomic embeddings (the endgame)

### Conditional Media VAE (NEW)

**Purpose**: Generate organism-specific growth media by conditioning on genome-derived features.

**Architecture**:
- **Input**: Genome k-mer embeddings (concatenated 4/7/8-mer profiles) + normalized media composition
- **Encoder**: Maps (genome, media) â†’ latent distribution q(z|genome, media)
- **Decoder**: Maps latent z + genome â†’ media reconstruction
- **Conditioning**: Genome embeddings injected at encoder input and decoder output for fine-grained control

**Training Strategy**: Curriculum learning
```
Phase 1: Bacteria (30K strains from BacDive)
    â†“ (evaluate per-organism accuracy)
Phase 2: Archaea (add thermophiles, halophiles)
    â†“
Phase 3: Fungi (Saccharomyces, Aspergillus, Candida)
    â†“
Phase 4: Protists (Tetrahymena, Paramecium)
```

**Features**:
- Multi-organism training reduces overfitting to bacterial genomes
- Curriculum prevents optimization collapse on rare organisms
- Enables zero-shot media prediction for novel organisms

**Module**: [src/models/media_generator.py](src/models/media_generator.py) â†’ `ConditionalMediaVAE` class

## Roadmap

- [x] Data ingestion from MediaDive REST API
- [x] SQLite storage with structured schema
- [x] Feature engineering pipeline (composition matrices, strain features)
- [x] Growth prediction models (sklearn + neural)
- [x] Media generation model (VAE)
- [x] Test suite (unit + integration + data integrity)
- [x] Cloud training support (Modal)
- [x] **BacDive API integration** (bacterial culturomics, 30K+ strains)
- [x] **NCBI E-utilities integration** (fungal & protist genomes)
- [x] **Growth condition enrichment** (taxonomy inference + literature mining)
- [x] **Conditional VAE with genome embeddings**
- [x] **Multi-organism training pipeline** (curriculum learning)
- [x] **Genome feature extraction** (k-mer embeddings)
- [ ] EDA notebooks (in progress)
- [ ] Hyperparameter sweep (Optuna / W&B Sweeps)
- [ ] Transformer-based sequence model for media recipes
- [ ] Wet-lab validation loop
- [ ] Active learning feedback from experimental results
- [ ] Zero-shot media prediction for uncultured organisms

## Data Sources

This project integrates data from multiple authoritative public databases:

| Database | Organisms | Records | Data |
|----------|-----------|---------|------|
| **BacDive** | Bacteria + Archaea | 30,000+ | Strains, growth conditions, media |
| **NCBI Assembly** | Fungi, Protists, Archaea | 1,000s | Genome metadata, taxonomy |
| **PubMed** | All | â€” | Growth parameters from literature |
| **MediaDive** | Bacterial | 10,000+ | Growth media formulations |

**See [`docs/guides/api_reference.md`](docs/guides/api_reference.md) for complete API documentation.**

### Setup Instructions

```bash
# 1. NCBI registration (optional, for higher rate limits)
# Create account: https://www.ncbi.nlm.nih.gov/account/
# Get API key: Account Settings â†’ API Key
# Add to .env: NCBI_API_KEY=your_key

# 2. Set your email (required for NCBI)
# Edit .env: NCBI_EMAIL=your.email@example.com

# 3. Run ingestion
make integrate-mediadive-ncbi
```

---

## Verification & Testing

### Verify Integration Works

```bash
# Quick verification script (checks files, imports, Makefile targets)
bash VERIFY_INTEGRATION.sh
```

**What it does**:
- âœ… Checks all required files exist
- âœ… Verifies Makefile targets are defined
- âœ… Tests Python imports work
- âœ… Shows quick start commands

**Is it necessary?** No, optional. Use it to verify the system is set up correctly before running the full pipeline.

### Run Tests

```bash
make test
```

Tests check:
- API client connectivity
- Database schema integrity
- Feature extraction correctness
- Model architectures
- Data ingestion quality
---

## Project Structure

```
mediadive-growth-db/
â”œâ”€â”€ README.md               â† You are here
â”œâ”€â”€ Makefile                â† Common commands
â”œâ”€â”€ pyproject.toml          â† Dependencies
â”‚
â”œâ”€â”€ docs/                   â† ğŸ“š All documentation
â”‚   â”œâ”€â”€ GETTING_STARTED.md  â† Start here!
â”‚   â”œâ”€â”€ INDEX.md            â† Navigation hub
â”‚   â”œâ”€â”€ COMMAND_REFERENCE.md
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md
â”‚   â”œâ”€â”€ guides/             â† Detailed guides
â”‚   â””â”€â”€ archive/            â† Historical docs
â”‚
â”œâ”€â”€ src/                    â† Source code
â”‚   â”œâ”€â”€ api/                â† MediaDive API client
â”‚   â”œâ”€â”€ db/                 â† Database & schema
â”‚   â”œâ”€â”€ ingest/             â† Data ingestion (MediaDive, BacDive, NCBI)
â”‚   â”œâ”€â”€ features/           â† Feature engineering
â”‚   â”œâ”€â”€ models/             â† ML models (CVAE, predictors)
â”‚   â””â”€â”€ training/           â† Training pipelines
â”‚
â”œâ”€â”€ scripts/                â† CLI entry points
â”‚   â”œâ”€â”€ run_ingest.py
â”‚   â”œâ”€â”€ integrate_mediadive_ncbi.py
â”‚   â”œâ”€â”€ train_cvae.py
â”‚   â””â”€â”€ ingest_all_organisms.py
â”‚
â”œâ”€â”€ notebooks/              â† Jupyter notebooks
â”‚   â”œâ”€â”€ mediadive_deep_learning_models.ipynb
â”‚   â””â”€â”€ top_media_analysis.ipynb
â”‚
â”œâ”€â”€ tests/                  â† Test suite
â”‚   â”œâ”€â”€ test_api_client.py
â”‚   â”œâ”€â”€ test_db.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_data_integrity.py
â”‚
â””â”€â”€ data/                   â† Data directory
    â”œâ”€â”€ raw/                â† Raw API cache & genomes
    â”œâ”€â”€ interim/            â† Intermediate processing
    â”œâ”€â”€ processed/          â† ML-ready datasets
    â”œâ”€â”€ models/             â† Trained models
    â””â”€â”€ releases/           â† Public releases
```

---

## Common Commands

```bash
# Setup
pip install -e ".[ml,viz,dev]"
make init-db

# Data ingestion
make integrate-mediadive-ncbi          # Latest: link MediaDive to NCBI
make ingest-all-organisms              # Alternative: multi-source ingest
make ingest                            # Legacy: MediaDive only

# Feature engineering
make features
make build-genome-embeddings

# Training
make train-cvae-all                    # Full curriculum learning
make train-cvae --organism bacteria    # Single organism
make train                             # sklearn baseline

# Verification
bash VERIFY_INTEGRATION.sh
make test

# Stats & debugging
make integrate-stats
make integrate-stats --verbose
```

ğŸ‘‰ **Full reference**: [`docs/COMMAND_REFERENCE.md`](docs/COMMAND_REFERENCE.md)

---

## Getting Help

| Need | Resource |
|------|----------|
| **Getting started** | [`docs/GETTING_STARTED.md`](docs/GETTING_STARTED.md) |
| **All commands** | [`docs/COMMAND_REFERENCE.md`](docs/COMMAND_REFERENCE.md) |
| **Stuck?** | [`docs/TROUBLESHOOTING.md`](docs/TROUBLESHOOTING.md) |
| **Full navigation** | [`docs/INDEX.md`](docs/INDEX.md) |
| **Integration guide** | [`docs/guides/mediadive_ncbi_linking.md`](docs/guides/mediadive_ncbi_linking.md) |
| **API reference** | [`docs/guides/api_reference.md`](docs/guides/api_reference.md) |
| **CVAE details** | [`docs/guides/CVAE_GUIDE.md`](docs/guides/CVAE_GUIDE.md) |

---

## Roadmap

- [x] Data ingestion from MediaDive REST API
- [x] SQLite storage with structured schema
- [x] Feature engineering pipeline (composition matrices, strain features)
- [x] Growth prediction models (sklearn + neural)
- [x] Media generation model (VAE)
- [x] Test suite (unit + integration + data integrity)
- [x] Cloud training support (Modal)
- [x] **BacDive API integration** (bacterial culturomics, 30K+ strains)
- [x] **NCBI E-utilities integration** (fungal & protist genomes)
- [x] **Growth condition enrichment** (taxonomy inference + literature mining)
- [x] **Conditional VAE with genome embeddings**
- [x] **Multi-organism training pipeline** (curriculum learning)
- [x] **Genome feature extraction** (k-mer embeddings)
- [x] **MediaDive-NCBI integration** (link + propagate + dataset)
- [ ] EDA notebooks (in progress)
- [ ] Hyperparameter sweep (Optuna / W&B Sweeps)
- [ ] Transformer-based sequence model for media recipes
- [ ] Wet-lab validation loop
- [ ] Active learning feedback from experimental results
- [ ] Zero-shot media prediction for uncultured organisms

---

**Status**: âœ… Production Ready  
**Last Updated**: 2024  
**Questions?** Start with [`docs/GETTING_STARTED.md`](docs/GETTING_STARTED.md) or [`docs/TROUBLESHOOTING.md`](docs/TROUBLESHOOTING.md)