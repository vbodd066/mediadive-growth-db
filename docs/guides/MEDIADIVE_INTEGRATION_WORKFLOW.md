# MediaDive-NCBI Integration: Complete Workflow

## Overview

This document shows the complete end-to-end workflow for building a rich training dataset by integrating MediaDive strain data with NCBI genomes.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Existing MediaDive Data                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  strains table               strain_growth table                   â”‚
â”‚  â”œâ”€ strain_id               â”œâ”€ strain_id (FK)                      â”‚
â”‚  â”œâ”€ species                 â”œâ”€ media_id (FK)                       â”‚
â”‚  â”œâ”€ ccno (culture collection)  â”œâ”€ growth (bool)                     â”‚
â”‚  â”œâ”€ domain                  â”œâ”€ growth_rate                         â”‚
â”‚  â””â”€ bacdive_id              â”œâ”€ growth_quality                      â”‚
â”‚                             â””â”€ modification                        â”‚
â”‚  media table                media_composition table                â”‚
â”‚  â”œâ”€ media_id               â”œâ”€ media_id (FK)                        â”‚
â”‚  â”œâ”€ media_name             â”œâ”€ ingredient_id (FK)                   â”‚
â”‚  â”œâ”€ min_pH, max_pH         â”œâ”€ g_per_l                              â”‚
â”‚  â””â”€ description            â””â”€ mmol_per_l                           â”‚
â”‚                                                                     â”‚
â”‚  ingredients table                                                  â”‚
â”‚  â”œâ”€ ingredient_id                                                   â”‚
â”‚  â”œâ”€ ingredient_name                                                 â”‚
â”‚  â”œâ”€ chebi_id, cas_rn, kegg_compound                                â”‚
â”‚  â””â”€ molar_mass, formula, density                                   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ NEW: LinkMediaDiveToGenomes Pipeline
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Phase 1: Link Species to NCBI                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  1. Extract unique species from strains table                        â”‚
â”‚     Result: [                                                        â”‚
â”‚       {species: "Escherichia coli", domain: "B", count: 150},       â”‚
â”‚       {species: "Bacillus subtilis", domain: "B", count: 89},       â”‚
â”‚       ...                                                            â”‚
â”‚     ]                                                                â”‚
â”‚                                                                      â”‚
â”‚  2. For each species:                                                â”‚
â”‚     a. Search NCBI Assembly: "{species}" AND "complete genome"       â”‚
â”‚     b. Filter reference genomes (high quality)                       â”‚
â”‚     c. Store in genomes table with strain_id FK                      â”‚
â”‚                                                                      â”‚
â”‚  Result: genomes table populated                                     â”‚
â”‚          5,000-7,000 species Ã— 1-3 genomes = 10,000-20,000 rows    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Phase 2: Propagate Growth Data to Genomes                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  For each strain with linked genomes:                                â”‚
â”‚                                                                      â”‚
â”‚    strain_growth                          genome_growth             â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚    strain_id â†’ media_id, growth           genome_id â†’ media_id      â”‚
â”‚         â”‚                                      â”‚                     â”‚
â”‚         â””â”€ join via â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚            strain.strain_id = genomes.strain_id                     â”‚
â”‚                                                                      â”‚
â”‚  Copy all observations:                                              â”‚
â”‚    INSERT INTO genome_growth                                        â”‚
â”‚    SELECT g.genome_id, sg.media_id, sg.growth,                     â”‚
â”‚           sg.growth_rate, confidence, 'mediadive'                  â”‚
â”‚    FROM genomes g                                                    â”‚
â”‚    JOIN strains s ON g.strain_id = s.strain_id                     â”‚
â”‚    JOIN strain_growth sg ON s.strain_id = sg.strain_id             â”‚
â”‚                                                                      â”‚
â”‚  Confidence mapping:                                                 â”‚
â”‚    excellent â†’ 0.95  |  good â†’ 0.85  |  fair â†’ 0.70  |  poor â†’ 0.50
â”‚                                                                      â”‚
â”‚  Result: genome_growth table populated                              â”‚
â”‚          10,000-50,000 training observations                        â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Phase 3: Build Composite Training Dataset                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Query: Get all linked genome-media pairs with metadata             â”‚
â”‚                                                                      â”‚
â”‚  SELECT                                                              â”‚
â”‚    g.genome_id, s.species, s.ccno,                                 â”‚
â”‚    m.media_id, m.media_name,                                       â”‚
â”‚    gg.growth, gg.confidence, gg.source,                            â”‚
â”‚    g.organism_type, g.gc_content, g.sequence_length,              â”‚
â”‚    GROUP_CONCAT(i.ingredient_name || '(' || mc.g_per_l || 'g/L')   â”‚
â”‚  FROM genome_growth gg                                              â”‚
â”‚  JOIN genomes g, strains s, media m, media_composition mc, ...     â”‚
â”‚                                                                      â”‚
â”‚  Output JSON with fields per pair:                                  â”‚
â”‚  {                                                                   â”‚
â”‚    "genome_id": "GCF_000005845.2",                                 â”‚
â”‚    "species": "Escherichia coli",                                  â”‚
â”‚    "strain_ccno": "K-12 substr. MG1655",                           â”‚
â”‚    "media_id": "48",                                                â”‚
â”‚    "media_name": "Luria Broth (LB)",                               â”‚
â”‚    "pH_min": 6.5,                                                   â”‚
â”‚    "pH_max": 8.0,                                                   â”‚
â”‚    "growth": true,                                                  â”‚
â”‚    "confidence": 0.95,                                              â”‚
â”‚    "organism_type": "bacteria",                                     â”‚
â”‚    "genome_gc_content": 50.8,                                       â”‚
â”‚    "genome_length": 4641652,                                        â”‚
â”‚    "ingredients": "peptone(10g/L);beef_extract(5g/L);NaCl(10g/L)", â”‚
â”‚    "ingredient_count": 3                                            â”‚
â”‚  }                                                                   â”‚
â”‚                                                                      â”‚
â”‚  Result: mediadive_ncbi_integrated_dataset.json                     â”‚
â”‚          10,000-50,000 complete training pairs                      â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Ready for CVAE Training                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  For each genome-media pair:                                         â”‚
â”‚                                                                      â”‚
â”‚    1. Load genome embeddings (k-mer 128-dim from genome_embeddings) â”‚
â”‚    2. Load media composition vector (from media_composition)        â”‚
â”‚    3. Create training example (X, y)                                â”‚
â”‚                                                                      â”‚
â”‚    X = [genome_embedding, media_composition]                        â”‚
â”‚    y = growth_label                                                 â”‚
â”‚                                                                      â”‚
â”‚  Split by organism type for curriculum learning:                    â”‚
â”‚                                                                      â”‚
â”‚    Phase 1: Bacteria     (8,000-12,000 pairs)                       â”‚
â”‚    Phase 2: Archaea      (500-1,000 pairs)                          â”‚
â”‚    Phase 3: Fungi        (1,000-2,000 pairs)                        â”‚
â”‚    Phase 4: Protists     (100-200 pairs)                            â”‚
â”‚                                                                      â”‚
â”‚  Training loop:                                                      â”‚
â”‚    for phase in [bacteria, archaea, fungi, protists]:               â”‚
â”‚        model = train_cvae(phase_pairs)                              â”‚
â”‚        evaluate_cross_organism_generalization()                     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Reference: Command Execution

```bash
# â”Œâ”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
cd mediadive-growth-db
cp .env.example .env
# Edit .env: add NCBI_EMAIL=your@email.com

# â”Œâ”€ Integration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

# Option 1: One command (full pipeline)
make integrate-mediadive-ncbi

# Option 2: Step-by-step
make integrate-link-species      # Phase 1: Link to NCBI
make integrate-propagate         # Phase 2: Propagate growth data
make integrate-stats             # Phase 3: View results

# â”Œâ”€ Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

# Extract genome embeddings (if needed)
make build-genome-embeddings

# Build features and dataset
make features

# Train CVAE with curriculum learning
make train-cvae-all
```

## Data Volumes: Before & After

### Before Integration (MediaDive Only)

```
Strains:                 5,000-10,000
â”œâ”€ Genomes:              0 (no genome data)
â””â”€ Growth observations:  10,000-50,000

Media types:             100-300
Ingredients:             500-1000
Training pairs:          âŒ Can't train CVAE (no genomes)
```

### After Integration (MediaDive + NCBI)

```
Strains:                 5,000-10,000
â”œâ”€ With genomes:         3,000-7,000 (60-70% coverage)
â”œâ”€ Genomes linked:       4,000-12,000
â””â”€ Growth observations:  10,000-50,000

Media types:             100-300
Ingredients:             500-1000
Training pairs:          âœ… 10,000-50,000 (genome, media, growth)

Organism types:
â”œâ”€ Bacteria:             8,000-12,000 pairs
â”œâ”€ Archaea:              500-1,000 pairs
â”œâ”€ Fungi:                1,000-2,000 pairs
â””â”€ Protists:             100-200 pairs

Ready for CVAE training: âœ… YES
```

## Key Features

### 1. Cross-Organism Data Linking

```
MediaDive Strain             â†’  NCBI Genomes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Escherichia coli K-12        â†’  GCF_000005845.2 (reference)
                             â†’  GCF_000017325.1 (other assembly)

Growth on LB medium          â†’  Genome embedding (k-mer 128-dim)
Growth on Nutrient medium    â†’  Media composition vector
Growth on M9 medium
```

### 2. Metadata Richness

Each training pair includes:
- âœ… Genome embedding (organism signature)
- âœ… Media composition (chemical specification)
- âœ… Growth label (binary observation)
- âœ… Confidence score (data quality)
- âœ… Temperature range (from media metadata)
- âœ… pH range (from media metadata)
- âœ… Ingredient list (from media formulation)
- âœ… Organism type (curriculum learning)
- âœ… GC content (genomic feature)
- âœ… Sequence length (genomic feature)

### 3. Quality Assurance

```
Confidence scoring:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Direct MediaDive observation        â”‚
â”œâ”€ excellent growth quality: 0.95     â”‚
â”œâ”€ good growth quality:      0.85     â”‚
â”œâ”€ fair growth quality:      0.70     â”‚
â”œâ”€ poor growth quality:      0.50     â”‚
â””â”€ default (unspecified):    0.75     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Deduplication:
â”œâ”€ Same strain-media pair: take highest confidence
â”œâ”€ Cross-database duplicates: merge with weighting
â””â”€ Organism name variants: normalize via NCBI taxonomy
```

## Expected Outcomes

### Dataset Statistics

```
Total genome-media pairs:    10,000-50,000
â”œâ”€ Positive growth:          6,000-35,000 (60-70%)
â””â”€ Negative growth:          4,000-15,000 (30-40%)

Organism distribution:
â”œâ”€ Bacteria:                 80% (most data)
â”œâ”€ Fungi:                    10%
â”œâ”€ Archaea:                  8%
â””â”€ Protists:                 2%

Media distribution:
â”œâ”€ LB medium:                15-20%
â”œâ”€ Nutrient medium:          10-15%
â”œâ”€ M9 medium:                5-10%
â”œâ”€ Specialized media:        50-70%
â””â”€ Total unique types:       100-300

Feature availability:
â”œâ”€ Genome embeddings:        100% (precomputed)
â”œâ”€ Media composition:        90-95%
â”œâ”€ pH metadata:              80-90%
â”œâ”€ Ingredient details:       95-99%
â””â”€ Temperature metadata:     Varies by media source
```

### Training Performance

**Phase 1 (Bacteria):**
- Training pairs: 8,000-12,000
- Expected loss: 0.15-0.20
- Training time (GPU): 1-2 hours
- Cross-organism accuracy: N/A (same organism type)

**Phase 2 (Archaea):**
- Training pairs: 500-1,000
- Expected loss: 0.18-0.23 (slightly higher, new patterns)
- Training time (GPU): 15-30 minutes
- Cross-organism accuracy: 70-80% (vs bacteria)

**Phase 3 (Fungi):**
- Training pairs: 1,000-2,000
- Expected loss: 0.20-0.25 (eukaryotic complexity)
- Training time (GPU): 30-60 minutes
- Cross-organism accuracy: 60-75% (vs bacteria)

**Phase 4 (Protists):**
- Training pairs: 100-200
- Expected loss: 0.22-0.28 (limited data, complex features)
- Training time (GPU): 5-10 minutes
- Cross-organism accuracy: 50-65% (vs bacteria)

## Usage in CVAE Training

```python
import json
import numpy as np
from torch.utils.data import DataLoader, TensorDataset

# Load integrated dataset
with open('data/processed/mediadive_ncbi_integrated_dataset.json') as f:
    data = json.load(f)

pairs = data['pairs']

# Split by organism type (curriculum learning)
pairs_by_type = {}
for pair in pairs:
    org_type = pair['organism_type']
    if org_type not in pairs_by_type:
        pairs_by_type[org_type] = []
    pairs_by_type[org_type].append(pair)

# Curriculum training
curriculum_order = ['bacteria', 'archea', 'fungi', 'protists']
model = ConditionalMediaVAE(...)

for phase, org_type in enumerate(curriculum_order, 1):
    print(f"\nPhase {phase}: Training on {org_type}")
    
    phase_pairs = pairs_by_type.get(org_type, [])
    if not phase_pairs:
        print(f"  No {org_type} data, skipping")
        continue
    
    print(f"  Training on {len(phase_pairs)} pairs")
    
    # Create data loaders
    genome_embeddings = [...]  # Load from database
    media_compositions = [...]  # Load from database
    growth_labels = [p['growth'] for p in phase_pairs]
    
    X = torch.cat([genome_embeddings, media_compositions], dim=1)
    y = torch.tensor(growth_labels, dtype=torch.float32)
    
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=64)
    
    # Train
    for epoch in range(50):
        train_loss = model.train_epoch(loader)
        print(f"  Epoch {epoch+1}: loss={train_loss:.4f}")
    
    # Validate
    val_loss = model.evaluate(phase_pairs)
    print(f"  Validation loss: {val_loss:.4f}")
    
    # Save checkpoint
    model.save(f'checkpoints/cvae_phase{phase}.pt')
```

## Quality Considerations

### Data Biases

1. **Model Organism Bias**: E. coli, S. cerevisiae over-represented
2. **Media Bias**: LB and standard media dominant
3. **Taxonomic Bias**: Culturable organisms only (excludes uncultured)
4. **Temporal Bias**: Historical data (older strains may have different characteristics)

### Mitigation

- Use confidence scores as weights in loss function
- Apply stratified sampling across organism types
- Data augmentation for rare organisms
- Curriculum learning to handle distribution shift

### Quality Checks

```sql
-- Check data balance
SELECT organism_type, COUNT(*) FROM genome_growth
WHERE source='mediadive'
GROUP BY organism_type;

-- Check confidence distribution
SELECT ROUND(confidence, 1), COUNT(*)
FROM genome_growth WHERE source='mediadive'
GROUP BY ROUND(confidence, 1);

-- Check positive/negative balance
SELECT growth, COUNT(*) FROM genome_growth
WHERE source='mediadive'
GROUP BY growth;
```

## Next Steps

1. âœ… **Execute integration**: `make integrate-mediadive-ncbi`
2. âœ… **Verify dataset**: `make integrate-stats`
3. âœ… **Build features**: `make features`
4. âœ… **Train CVAE**: `make train-cvae-all`
5. ğŸ”„ **Evaluate**: Cross-organism generalization metrics
6. ğŸ”„ **Iterate**: Tune curriculum schedule, model architecture

## See Also

- [MEDIADIVE_NCBI_INTEGRATION.md](MEDIADIVE_NCBI_INTEGRATION.md) - Detailed guide
- [CVAE_IMPLEMENTATION.md](CVAE_IMPLEMENTATION.md) - Model architecture
- [DATA_SOURCES.md](DATA_SOURCES.md) - API integration
- [QUICK_START.md](QUICK_START.md) - Commands reference

---

**Status**: âœ… Ready to execute

**Command**: `make integrate-mediadive-ncbi`
